---
id: STORY-008-01
parent_epic: EPIC-008
status: Draft
actor: Backend Developer
complexity: Low (1 file)
---
# STORY-008-01: Metric Snapshot System

## 1. The Spec (The Contract)

### 1.1 User Story
**As a** Backend Developer,
**I want** a metric snapshot system that extracts key metrics from an analysis report and stores them as timestamped records in the metrics_history table,
**So that** the trends engine can compute deltas over time and the Trends page can render historical charts.

### 1.2 Detailed Requirements
- **Requirement 1**: Implement `captureSnapshot(repoId: string, analysisReport: AnalysisReport): MetricSnapshot` that extracts key metrics from an analysis report and stores them in the `metrics_history` table.
- **Requirement 2**: Extract the following metrics from the analysis report: `avgComplexity`, `maxComplexity`, `duplicationPercentage`, `totalFiles`, `totalLines`, `avgFileSize`, `errorPatternCount`, `dependencyCount`.
- **Requirement 3**: Store the metrics as a JSON blob in the `metrics_history.metrics` column alongside a `repo_id` and `timestamp` (ISO 8601).
- **Requirement 4**: The `captureSnapshot` function should be called automatically after every successful analysis run — integrate it into the analyzer engine's post-analysis hook.
- **Requirement 5**: Return the created `MetricSnapshot` record (id, repoId, timestamp, metrics) to the caller.
- **Requirement 6**: Implement `getSnapshots(repoId: string, since?: string): MetricSnapshot[]` that retrieves historical snapshots for a repo, optionally filtered by a "since" date.
- **Requirement 7**: If the analysis report is missing a metric (e.g., no complexity data), store `null` for that metric rather than omitting the key — ensures consistent JSON shape across snapshots.

---

## 2. The Truth (Executable Tests)

### 2.1 Acceptance Criteria (Gherkin)
```gherkin
Feature: Metric Snapshot System

  Scenario: Capture a snapshot from an analysis report
    Given an analysis report with avgComplexity 5.2, maxComplexity 15, duplicationPercentage 8.3
    When I call captureSnapshot("repo-1", analysisReport)
    Then a record is inserted into metrics_history with repo_id "repo-1"
    And the metrics JSON contains avgComplexity: 5.2, maxComplexity: 15, duplicationPercentage: 8.3
    And the timestamp is approximately now (within 1 second)

  Scenario: All metrics are captured
    Given a complete analysis report with all metric fields populated
    When I call captureSnapshot
    Then the metrics JSON contains all 8 metric keys: avgComplexity, maxComplexity, duplicationPercentage, totalFiles, totalLines, avgFileSize, errorPatternCount, dependencyCount

  Scenario: Missing metrics stored as null
    Given an analysis report with no complexity data (complexity module returned no results)
    When I call captureSnapshot
    Then the metrics JSON has avgComplexity: null and maxComplexity: null
    And other populated metrics are stored correctly

  Scenario: Automatic capture after analysis
    Given the analyzer engine completes a full analysis of repo "repo-1"
    When the analysis finishes successfully
    Then captureSnapshot is called automatically
    And a new metrics_history record exists for "repo-1"

  Scenario: Retrieve historical snapshots
    Given repo "repo-1" has 5 snapshots over the past month
    When I call getSnapshots("repo-1")
    Then all 5 snapshots are returned ordered by timestamp ascending

  Scenario: Retrieve snapshots with date filter
    Given repo "repo-1" has snapshots from Jan 1, Jan 15, Feb 1, Feb 15
    When I call getSnapshots("repo-1", "2026-02-01T00:00:00Z")
    Then only the Feb 1 and Feb 15 snapshots are returned
```

### 2.2 Verification Steps
- [ ] `captureSnapshot` inserts a record into `metrics_history` with correct repo_id and timestamp.
- [ ] The metrics JSON blob contains all 8 required metric keys.
- [ ] Missing metrics are stored as `null`, not omitted.
- [ ] `captureSnapshot` is called automatically after each successful analysis run.
- [ ] `getSnapshots` returns all records ordered by timestamp ascending.
- [ ] `getSnapshots` with a `since` parameter filters correctly.
- [ ] Returned `MetricSnapshot` objects have correct id, repoId, timestamp, and parsed metrics.

---

## 3. The Implementation Guide (AI-to-AI)

### 3.1 Context & Files
- **Primary Files**: `src/server/analyzer/snapshots.ts` (create)
- **Related Files**:
  - `src/server/analyzer/engine.ts` (existing — add post-analysis hook to call `captureSnapshot`)
  - `src/server/db/queries.ts` (existing — add snapshot query functions)
  - `src/server/db/schema.ts` (existing — `metrics_history` table already defined in PRD)
- **New Files Needed**:
  - `src/server/analyzer/snapshots.ts`

### 3.2 Technical Logic

**Step 1: Define types**

```typescript
// src/server/analyzer/snapshots.ts

export interface MetricValues {
  avgComplexity: number | null;
  maxComplexity: number | null;
  duplicationPercentage: number | null;
  totalFiles: number | null;
  totalLines: number | null;
  avgFileSize: number | null;
  errorPatternCount: number | null;
  dependencyCount: number | null;
}

export interface MetricSnapshot {
  id: number;
  repoId: string;
  timestamp: string;          // ISO 8601
  metrics: MetricValues;
}

// The AnalysisReport type comes from the analyzer engine (EPIC-005).
// It typically looks like:
export interface AnalysisReport {
  complexity?: {
    average: number;
    max: number;
    files: Array<{ path: string; complexity: number }>;
  };
  duplication?: {
    percentage: number;
    clones: Array<{ sourceFile: string; targetFile: string; lines: number }>;
  };
  fileStats?: {
    totalFiles: number;
    totalLines: number;
    averageFileSize: number;
  };
  errorPatterns?: {
    count: number;
    patterns: Array<{ pattern: string; file: string; line: number }>;
  };
  dependencies?: {
    count: number;
    list: Array<{ name: string; version: string }>;
  };
}
```

**Step 2: Implement metric extraction**

```typescript
function extractMetrics(report: AnalysisReport): MetricValues {
  return {
    avgComplexity: report.complexity?.average ?? null,
    maxComplexity: report.complexity?.max ?? null,
    duplicationPercentage: report.duplication?.percentage ?? null,
    totalFiles: report.fileStats?.totalFiles ?? null,
    totalLines: report.fileStats?.totalLines ?? null,
    avgFileSize: report.fileStats?.averageFileSize ?? null,
    errorPatternCount: report.errorPatterns?.count ?? null,
    dependencyCount: report.dependencies?.count ?? null,
  };
}
```

**Step 3: Implement `captureSnapshot`**

```typescript
import { db } from '../db/schema.js';

export function captureSnapshot(
  repoId: string,
  analysisReport: AnalysisReport
): MetricSnapshot {
  const metrics = extractMetrics(analysisReport);
  const timestamp = new Date().toISOString();

  const stmt = db.prepare(`
    INSERT INTO metrics_history (repo_id, timestamp, metrics)
    VALUES (?, ?, ?)
  `);

  const result = stmt.run(repoId, timestamp, JSON.stringify(metrics));

  return {
    id: result.lastInsertRowid as number,
    repoId,
    timestamp,
    metrics,
  };
}
```

**Step 4: Implement `getSnapshots`**

```typescript
export function getSnapshots(
  repoId: string,
  since?: string
): MetricSnapshot[] {
  let query: string;
  let params: unknown[];

  if (since) {
    query = `
      SELECT id, repo_id, timestamp, metrics
      FROM metrics_history
      WHERE repo_id = ? AND timestamp >= ?
      ORDER BY timestamp ASC
    `;
    params = [repoId, since];
  } else {
    query = `
      SELECT id, repo_id, timestamp, metrics
      FROM metrics_history
      WHERE repo_id = ?
      ORDER BY timestamp ASC
    `;
    params = [repoId];
  }

  const stmt = db.prepare(query);
  const rows = stmt.all(...params) as Array<{
    id: number;
    repo_id: string;
    timestamp: string;
    metrics: string;
  }>;

  return rows.map(row => ({
    id: row.id,
    repoId: row.repo_id,
    timestamp: row.timestamp,
    metrics: JSON.parse(row.metrics) as MetricValues,
  }));
}
```

**Step 5: Integrate into the analyzer engine**

```typescript
// In src/server/analyzer/engine.ts, add after analysis completes:
import { captureSnapshot } from './snapshots.js';

// Inside runAnalysis() or the orchestrator function, after all modules finish:
export async function runAnalysis(
  repoPath: string,
  options?: AnalysisOptions
): Promise<AnalysisReport> {
  // ... existing analysis logic ...
  const report = { complexity, duplication, fileStats, errorPatterns, dependencies };

  // Auto-capture snapshot after successful analysis
  // Only capture for full-repo analyses (not scoped branch analyses)
  if (!options?.scopeToFiles) {
    // Look up repoId from the repos table by path
    const repo = getRepoByPath(repoPath);
    if (repo) {
      captureSnapshot(repo.id, report);
    }
  }

  return report;
}
```

**Step 6: Ensure the metrics_history table has an index**

```sql
-- In src/server/db/schema.ts, ensure this index is created:
CREATE INDEX IF NOT EXISTS idx_metrics_history_repo_time
  ON metrics_history(repo_id, timestamp ASC);
```

### 3.3 API Contract
N/A — this is an internal module. The `captureSnapshot` function is called by the analyzer engine. The `getSnapshots` function is consumed by the trends computation module (STORY-008-02) and the trends API (STORY-008-03).

---

## 4. Definition of Done (The Gate)
- [ ] `src/server/analyzer/snapshots.ts` exists and exports `captureSnapshot`, `getSnapshots`, `MetricSnapshot`, `MetricValues`.
- [ ] `captureSnapshot` correctly extracts 8 metrics from an analysis report and stores them in `metrics_history`.
- [ ] Missing metrics are stored as `null` in the JSON blob.
- [ ] `captureSnapshot` is called automatically after every successful full-repo analysis in `engine.ts`.
- [ ] `getSnapshots` returns records ordered by timestamp ascending with parsed metrics.
- [ ] `getSnapshots` supports optional `since` date filtering.
- [ ] An index exists on `metrics_history(repo_id, timestamp)` for efficient queries.
- [ ] No TypeScript compilation errors (`npx tsc --noEmit`).

---
id: STORY-001-04
parent_epic: EPIC-001
status: Draft
actor: Backend Developer
complexity: Medium (2-3 files)
---
# STORY-001-04: SQLite Database Schema & Query Layer

## 1. The Spec (The Contract)

### 1.1 User Story
**As a** Backend Developer,
**I want** a SQLite database with a defined schema and a typed query helper layer,
**So that** all server-side features have a reliable, typed persistence layer they can depend on without reimplementing database access.

### 1.2 Detailed Requirements
- **Requirement 1**: Create `src/server/db/schema.ts` that creates and initializes the SQLite database file.
- **Requirement 2**: Database file location is `~/.vibelint/vibelint.db`. Create the `~/.vibelint/` directory if it does not exist.
- **Requirement 3**: Define the following tables with WAL journal mode:
  - `repos` — id TEXT PK, path TEXT NOT NULL UNIQUE, name TEXT NOT NULL, languages TEXT (JSON array), platform TEXT, injected_at TEXT, created_at TEXT NOT NULL, last_scan_at TEXT
  - `metrics_history` — id INTEGER PK AUTOINCREMENT, repo_id TEXT FK references repos(id), timestamp TEXT NOT NULL, metrics TEXT (JSON blob)
  - `analyses` — id INTEGER PK AUTOINCREMENT, repo_id TEXT FK references repos(id), branch TEXT, base_branch TEXT, diff_stats TEXT (JSON blob), analysis_data TEXT (JSON blob), created_at TEXT NOT NULL
  - `config` — key TEXT PK, value TEXT NOT NULL
- **Requirement 4**: Create `src/server/db/queries.ts` with typed helper functions: `getDb()`, `initDb()`, `getConfig(key)`, `setConfig(key, value)`, and repo CRUD stubs (`createRepo`, `getRepo`, `listRepos`, `deleteRepo`, `updateRepo`).
- **Requirement 5**: Use `better-sqlite3` (synchronous API).
- **Requirement 6**: Export TypeScript interfaces for all table row types.
- **Requirement 7**: Create a `schema_version` table to track the current schema version. On startup, compare the stored version against the expected version and run pending migrations in order.
- **Requirement 8**: Run `PRAGMA integrity_check` on startup. If the database is corrupted, log a clear error and offer a recovery path (rename corrupted file, create fresh DB).
- **Requirement 9**: Create a periodic backup of the database to `~/.vibelint/vibelint.db.bak` on each successful startup (copy the existing file before opening).

---

## 2. The Truth (Executable Tests)

### 2.1 Acceptance Criteria (Gherkin)
```gherkin
Feature: SQLite Database Schema & Query Layer

  Scenario: Database initializes on first run
    Given the ~/.vibelint/ directory does not exist
    When initDb() is called
    Then the ~/.vibelint/ directory is created
    And the vibelint.db file is created inside it
    And all four tables (repos, metrics_history, analyses, config) exist

  Scenario: Config CRUD works
    Given the database is initialized
    When setConfig("wizard_complete", "true") is called
    Then getConfig("wizard_complete") returns "true"

  Scenario: Repo CRUD works
    Given the database is initialized
    When createRepo({ id, path, name, languages, created_at }) is called
    Then getRepo(id) returns the inserted row
    And listRepos() includes the new repo
    When deleteRepo(id) is called
    Then getRepo(id) returns undefined

  Scenario: WAL mode is enabled
    Given the database is initialized
    When I query "PRAGMA journal_mode"
    Then the result is "wal"

  Scenario: Foreign key constraints are enforced
    Given the database is initialized
    When I try to insert a metrics_history row with a non-existent repo_id
    Then the insert fails with a foreign key constraint error

  Scenario: Schema version is tracked
    Given the database is initialized for the first time
    When I query the schema_version table
    Then the current version matches the latest migration version

  Scenario: Database integrity is checked on startup
    Given an existing database file at ~/.vibelint/vibelint.db
    When initDb() is called
    Then PRAGMA integrity_check is run
    And if the check fails, a clear error is logged with recovery instructions

  Scenario: Migrations run on version upgrade
    Given an existing database at schema version 1
    And the application expects schema version 2
    When initDb() is called
    Then migration from version 1 to 2 is applied
    And the schema_version table is updated to version 2

  Scenario: Database backup on startup
    Given an existing database file at ~/.vibelint/vibelint.db
    When initDb() is called
    Then a backup copy exists at ~/.vibelint/vibelint.db.bak
```

### 2.2 Verification Steps
- [ ] `initDb()` creates the database file at `~/.vibelint/vibelint.db`.
- [ ] All four tables exist (verified via `.tables` or `SELECT name FROM sqlite_master`).
- [ ] `setConfig` / `getConfig` round-trips a value.
- [ ] `createRepo` / `getRepo` / `listRepos` / `deleteRepo` work.
- [ ] `PRAGMA journal_mode` returns `wal`.
- [ ] `PRAGMA foreign_keys` returns `1`.

---

## 3. The Implementation Guide (AI-to-AI)

### 3.1 Context & Files
- **Primary Files**:
  - `src/server/db/schema.ts`
  - `src/server/db/queries.ts`
- **Related Files**: `package.json` (already has `better-sqlite3` from STORY-001-01)
- **New Files Needed**: Yes — both files listed above

### 3.2 Technical Logic

**Step 1: Define TypeScript types in `src/server/db/schema.ts`**

```typescript
import Database from 'better-sqlite3';
import path from 'node:path';
import os from 'node:os';
import fs from 'node:fs';

// --- Types ---

export interface RepoRow {
  id: string;
  path: string;
  name: string;
  languages: string;       // JSON stringified string[]
  platform: string | null;
  injected_at: string | null;
  created_at: string;
  last_scan_at: string | null;
}

export interface MetricsHistoryRow {
  id: number;
  repo_id: string;
  timestamp: string;
  metrics: string;          // JSON blob
}

export interface AnalysisRow {
  id: number;
  repo_id: string;
  branch: string | null;
  base_branch: string | null;
  diff_stats: string | null; // JSON blob
  analysis_data: string | null; // JSON blob
  created_at: string;
}

export interface ConfigRow {
  key: string;
  value: string;
}

// --- Schema Initialization ---

const DB_DIR = path.join(os.homedir(), '.vibelint');
const DB_PATH = path.join(DB_DIR, 'vibelint.db');

export function getDbPath(): string {
  return DB_PATH;
}

/**
 * Back up existing database before opening.
 */
function backupDatabase(): void {
  if (fs.existsSync(DB_PATH)) {
    fs.copyFileSync(DB_PATH, `${DB_PATH}.bak`);
  }
}

/**
 * Run integrity check on the database. If corrupted, rename and start fresh.
 */
function checkIntegrity(db: Database.Database): void {
  const result = db.pragma('integrity_check') as { integrity_check: string }[];
  const status = result[0]?.integrity_check;
  if (status !== 'ok') {
    console.error(`Database integrity check failed: ${status}`);
    console.error('Renaming corrupted database and creating a fresh one.');
    db.close();
    const corruptPath = `${DB_PATH}.corrupt.${Date.now()}`;
    fs.renameSync(DB_PATH, corruptPath);
    console.error(`Corrupted database saved as: ${corruptPath}`);
    throw new Error('DATABASE_CORRUPTED');
  }
}

// --- Migration System ---

const CURRENT_SCHEMA_VERSION = 1;

interface Migration {
  version: number;
  description: string;
  up: (db: Database.Database) => void;
}

/**
 * v1: Initial schema (repos, metrics_history, analyses, config).
 * Future migrations are appended here. Each must be idempotent.
 */
const MIGRATIONS: Migration[] = [
  {
    version: 1,
    description: 'Initial schema',
    up: (db) => {
      db.exec(`
        CREATE TABLE IF NOT EXISTS repos (
          id TEXT PRIMARY KEY,
          path TEXT NOT NULL UNIQUE,
          name TEXT NOT NULL,
          languages TEXT DEFAULT '[]',
          platform TEXT,
          injected_at TEXT,
          created_at TEXT NOT NULL,
          last_scan_at TEXT
        );

        CREATE TABLE IF NOT EXISTS metrics_history (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          repo_id TEXT NOT NULL,
          timestamp TEXT NOT NULL,
          metrics TEXT,
          FOREIGN KEY (repo_id) REFERENCES repos(id) ON DELETE CASCADE
        );

        CREATE TABLE IF NOT EXISTS analyses (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          repo_id TEXT NOT NULL,
          branch TEXT,
          base_branch TEXT,
          diff_stats TEXT,
          analysis_data TEXT,
          created_at TEXT NOT NULL,
          FOREIGN KEY (repo_id) REFERENCES repos(id) ON DELETE CASCADE
        );

        CREATE TABLE IF NOT EXISTS config (
          key TEXT PRIMARY KEY,
          value TEXT NOT NULL
        );
      `);
    },
  },
  // Future migrations go here:
  // { version: 2, description: '...', up: (db) => { ... } },
];

function runMigrations(db: Database.Database): void {
  // Ensure schema_version table exists
  db.exec(`
    CREATE TABLE IF NOT EXISTS schema_version (
      version INTEGER PRIMARY KEY,
      applied_at TEXT NOT NULL,
      description TEXT
    );
  `);

  const currentVersion = (
    db.prepare('SELECT MAX(version) as v FROM schema_version').get() as { v: number | null }
  ).v ?? 0;

  const pending = MIGRATIONS.filter((m) => m.version > currentVersion);

  for (const migration of pending) {
    migration.up(db);
    db.prepare(
      'INSERT INTO schema_version (version, applied_at, description) VALUES (?, ?, ?)'
    ).run(migration.version, new Date().toISOString(), migration.description);
  }
}

export function createDatabase(): Database.Database {
  // Ensure directory exists
  if (!fs.existsSync(DB_DIR)) {
    fs.mkdirSync(DB_DIR, { recursive: true });
  }

  // Backup existing database before opening
  backupDatabase();

  const db = new Database(DB_PATH);

  // Enable WAL mode and foreign keys
  db.pragma('journal_mode = WAL');
  db.pragma('foreign_keys = ON');

  // Check integrity of existing database
  try {
    checkIntegrity(db);
  } catch (err) {
    if (err instanceof Error && err.message === 'DATABASE_CORRUPTED') {
      // Reopen fresh database
      const freshDb = new Database(DB_PATH);
      freshDb.pragma('journal_mode = WAL');
      freshDb.pragma('foreign_keys = ON');
      runMigrations(freshDb);
      return freshDb;
    }
    throw err;
  }

  // Run pending migrations
  runMigrations(db);

  return db;
}

// NOTE: The inline CREATE TABLE statements below are REPLACED by the migration
// system above. The createDatabase() function now delegates to runMigrations()
// which handles all schema creation and upgrades. The old inline approach is
// removed to prevent confusion.
      id TEXT PRIMARY KEY,
      path TEXT NOT NULL UNIQUE,
      name TEXT NOT NULL,
      languages TEXT DEFAULT '[]',
      platform TEXT,
      injected_at TEXT,
      created_at TEXT NOT NULL,
      last_scan_at TEXT
    );

    CREATE TABLE IF NOT EXISTS metrics_history (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      repo_id TEXT NOT NULL,
      timestamp TEXT NOT NULL,
      metrics TEXT,
      FOREIGN KEY (repo_id) REFERENCES repos(id) ON DELETE CASCADE
    );

    CREATE TABLE IF NOT EXISTS analyses (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      repo_id TEXT NOT NULL,
      branch TEXT,
      base_branch TEXT,
      diff_stats TEXT,
      analysis_data TEXT,
      created_at TEXT NOT NULL,
      FOREIGN KEY (repo_id) REFERENCES repos(id) ON DELETE CASCADE
    );

    CREATE TABLE IF NOT EXISTS config (
      key TEXT PRIMARY KEY,
      value TEXT NOT NULL
    );
  `);

  return db;
}
```

**Step 2: Create query helpers in `src/server/db/queries.ts`**

```typescript
import type Database from 'better-sqlite3';
import { createDatabase, type RepoRow, type ConfigRow } from './schema.js';

let _db: Database.Database | null = null;

/**
 * Get or initialize the singleton database instance.
 */
export function getDb(): Database.Database {
  if (!_db) {
    _db = createDatabase();
  }
  return _db;
}

/**
 * Explicitly initialize the database (call at server startup).
 */
export function initDb(): Database.Database {
  return getDb();
}

// --- Config helpers ---

export function getConfig(key: string): string | undefined {
  const db = getDb();
  const row = db.prepare('SELECT value FROM config WHERE key = ?').get(key) as ConfigRow | undefined;
  return row?.value;
}

export function setConfig(key: string, value: string): void {
  const db = getDb();
  db.prepare(
    'INSERT INTO config (key, value) VALUES (?, ?) ON CONFLICT(key) DO UPDATE SET value = excluded.value'
  ).run(key, value);
}

export function getAllConfig(): Record<string, string> {
  const db = getDb();
  const rows = db.prepare('SELECT key, value FROM config').all() as ConfigRow[];
  return Object.fromEntries(rows.map((r) => [r.key, r.value]));
}

// --- Repo helpers ---

export interface CreateRepoInput {
  id: string;
  path: string;
  name: string;
  languages: string[];
  platform?: string | null;
}

export function createRepo(input: CreateRepoInput): RepoRow {
  const db = getDb();
  const now = new Date().toISOString();
  db.prepare(`
    INSERT INTO repos (id, path, name, languages, platform, created_at, last_scan_at)
    VALUES (?, ?, ?, ?, ?, ?, ?)
  `).run(
    input.id,
    input.path,
    input.name,
    JSON.stringify(input.languages),
    input.platform ?? null,
    now,
    now,
  );
  return getRepo(input.id)!;
}

export function getRepo(id: string): RepoRow | undefined {
  const db = getDb();
  return db.prepare('SELECT * FROM repos WHERE id = ?').get(id) as RepoRow | undefined;
}

export function listRepos(): RepoRow[] {
  const db = getDb();
  return db.prepare('SELECT * FROM repos ORDER BY created_at DESC').all() as RepoRow[];
}

export function deleteRepo(id: string): boolean {
  const db = getDb();
  const result = db.prepare('DELETE FROM repos WHERE id = ?').run(id);
  return result.changes > 0;
}

export function updateRepo(id: string, fields: Partial<Pick<RepoRow, 'languages' | 'platform' | 'last_scan_at' | 'injected_at'>>): RepoRow | undefined {
  const db = getDb();
  const sets: string[] = [];
  const values: unknown[] = [];

  if (fields.languages !== undefined) {
    sets.push('languages = ?');
    values.push(fields.languages);
  }
  if (fields.platform !== undefined) {
    sets.push('platform = ?');
    values.push(fields.platform);
  }
  if (fields.last_scan_at !== undefined) {
    sets.push('last_scan_at = ?');
    values.push(fields.last_scan_at);
  }
  if (fields.injected_at !== undefined) {
    sets.push('injected_at = ?');
    values.push(fields.injected_at);
  }

  if (sets.length === 0) return getRepo(id);

  values.push(id);
  db.prepare(`UPDATE repos SET ${sets.join(', ')} WHERE id = ?`).run(...values);
  return getRepo(id);
}
```

**Step 3: Register DB initialization in the server startup**

In `src/server/index.ts` (from STORY-001-03), add to `createServer()`:

```typescript
import { initDb } from './db/queries.js';

// Inside createServer(), before route registration:
initDb();
```

### 3.3 API Contract
N/A — this story provides an internal query layer. API routes consuming this layer are in EPIC-002 stories.

---

## 4. Definition of Done (The Gate)
- [ ] `src/server/db/schema.ts` exists and exports types + `createDatabase()`.
- [ ] `src/server/db/queries.ts` exists and exports `getDb()`, `initDb()`, config helpers, and repo CRUD functions.
- [ ] Running `initDb()` creates `~/.vibelint/vibelint.db` with all 4 tables + `schema_version` table.
- [ ] WAL journal mode is enabled (`PRAGMA journal_mode` returns `wal`).
- [ ] Foreign keys are enforced (`PRAGMA foreign_keys` returns `1`).
- [ ] Config round-trip works: `setConfig("test_key", "test_value")` followed by `getConfig("test_key")` returns `"test_value"`.
- [ ] Repo CRUD round-trip works: create, get, list, delete.
- [ ] `schema_version` table tracks the current version and migration runner applies pending migrations.
- [ ] `PRAGMA integrity_check` runs on startup; corrupted DB is renamed and a fresh one created.
- [ ] Existing DB is backed up to `vibelint.db.bak` on startup.
- [ ] All TypeScript types compile without errors.

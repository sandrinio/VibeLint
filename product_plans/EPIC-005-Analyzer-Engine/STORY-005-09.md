---
id: STORY-005-09
parent_epic: EPIC-005
status: Draft
actor: Backend Developer
complexity: Medium (2-3 files)
---
# STORY-005-09: Analysis API

## 1. The Spec (The Contract)

### 1.1 User Story
**As a** Backend Developer,
**I want** Fastify REST API endpoints to trigger analysis runs, retrieve the latest results, list analysis history, and fetch specific analysis details,
**So that** the frontend Analysis View and any external tooling can interact with the analyzer engine over HTTP.

### 1.2 Detailed Requirements
- **Requirement 1**: `POST /api/repos/:repoId/analyze` — triggers a new analysis run for the specified repo. Returns `202 Accepted` with the analysis ID immediately. The analysis runs asynchronously. For small repos, the analysis may complete by the time the response is returned (in which case, return `200 OK` with full results).
- **Requirement 2**: `GET /api/repos/:repoId/analysis/latest` — returns the most recent analysis results from the database for the given repo. Returns `404` if no analysis has been run.
- **Requirement 3**: `GET /api/repos/:repoId/analysis/history` — returns a list of past analysis runs: `{ id, timestamp, branch, overallStatus, durationMs }`. Supports optional query parameter `?limit=N` (default: 20).
- **Requirement 4**: `GET /api/repos/:repoId/analysis/:analysisId` — returns the full analysis detail for a specific analysis run. Returns `404` if not found.
- **Requirement 5**: Validate that the `repoId` exists in the `repos` table before processing. Return `404` with `{ error: 'Repository not found' }` if it does not exist.
- **Requirement 6**: Register as a Fastify plugin that can be mounted on the server's route tree.
- **Requirement 7**: Analysis trigger accepts optional JSON body: `{ baseBranch?: string, config?: Partial<AnalysisConfig> }` to override defaults.

---

## 2. The Truth (Executable Tests)

### 2.1 Acceptance Criteria (Gherkin)
```gherkin
Feature: Analysis REST API

  Scenario: Trigger analysis
    Given a repo with id "repo-123" exists in the database
    When I POST /api/repos/repo-123/analyze
    Then the response status is 202
    And the response body contains { analysisId, status: "running" }
    And an analysis run is initiated in the background

  Scenario: Get latest analysis
    Given a repo "repo-123" has a completed analysis
    When I GET /api/repos/repo-123/analysis/latest
    Then the response status is 200
    And the response body contains the full AnalysisReport JSON

  Scenario: No analysis exists yet
    Given a repo "repo-123" has no completed analyses
    When I GET /api/repos/repo-123/analysis/latest
    Then the response status is 404
    And the response body contains { error: "No analysis found" }

  Scenario: List analysis history
    Given a repo "repo-123" has 5 completed analyses
    When I GET /api/repos/repo-123/analysis/history?limit=3
    Then the response status is 200
    And the response body contains an array of 3 analysis summaries
    And summaries are ordered by timestamp descending

  Scenario: Get specific analysis by ID
    Given an analysis with id 42 exists for repo "repo-123"
    When I GET /api/repos/repo-123/analysis/42
    Then the response status is 200
    And the response body contains the full analysis detail

  Scenario: Repo not found
    Given no repo with id "nonexistent" exists
    When I POST /api/repos/nonexistent/analyze
    Then the response status is 404
    And the response body contains { error: "Repository not found" }

  Scenario: Trigger analysis with custom config
    Given a repo "repo-123" exists
    When I POST /api/repos/repo-123/analyze with body { baseBranch: "main", config: { complexity: { warnThreshold: 8 } } }
    Then the analysis uses "main" as the base branch
    And the complexity warn threshold is set to 8
```

### 2.2 Verification Steps
- [ ] `POST /api/repos/:repoId/analyze` triggers an analysis run and returns 202.
- [ ] `GET /api/repos/:repoId/analysis/latest` returns the most recent analysis.
- [ ] `GET /api/repos/:repoId/analysis/history` returns paginated history.
- [ ] `GET /api/repos/:repoId/analysis/:analysisId` returns a specific analysis.
- [ ] Invalid repo IDs return 404.
- [ ] Analysis results are stored in SQLite and retrievable.
- [ ] Custom config overrides are applied to the analysis run.

---

## 3. The Implementation Guide (AI-to-AI)

### 3.1 Context & Files
- **Primary Files**: `src/server/api/analysis.ts` (create)
- **Related Files**:
  - `src/server/analyzer/engine.ts` (STORY-005-08 — `runAnalysis`, `generateReport`, etc.)
  - `src/server/db/queries.ts` (database queries — from EPIC-001)
  - `src/server/index.ts` (Fastify server — register plugin)
- **New Files Needed**:
  - `src/server/api/analysis.ts`
  - `tests/server/api/analysis.test.ts`

### 3.2 Technical Logic

**Step 1: Define the Fastify plugin**

```typescript
// src/server/api/analysis.ts

import { FastifyInstance, FastifyRequest, FastifyReply } from 'fastify';
import {
  runAnalysis,
  generateReport,
  writeReportToRepo,
  saveAnalysisToDb,
  saveMetricsSnapshot,
  AnalysisConfig,
  DEFAULT_ANALYSIS_CONFIG,
  AnalysisReport,
} from '../analyzer/engine.js';

// Track in-progress analysis runs
const runningAnalyses = new Map<string, { promise: Promise<AnalysisReport>; startedAt: string }>();

export default async function analysisRoutes(fastify: FastifyInstance): Promise<void> {
  const db = fastify.db; // Assumes db is decorated on the Fastify instance

  // ── POST /api/repos/:repoId/analyze ──────────────────────────
  fastify.post<{
    Params: { repoId: string };
    Body: { baseBranch?: string; config?: Partial<AnalysisConfig> };
  }>('/api/repos/:repoId/analyze', async (request, reply) => {
    const { repoId } = request.params;

    // Validate repo exists
    const repo = db.prepare('SELECT * FROM repos WHERE id = ?').get(repoId);
    if (!repo) {
      return reply.status(404).send({ error: 'Repository not found' });
    }

    // Check if analysis is already running for this repo
    if (runningAnalyses.has(repoId)) {
      return reply.status(409).send({
        error: 'Analysis already in progress',
        startedAt: runningAnalyses.get(repoId)!.startedAt,
      });
    }

    // Merge config with defaults
    const body = request.body || {};
    const config: AnalysisConfig = {
      ...DEFAULT_ANALYSIS_CONFIG,
      ...body.config,
      baseBranch: body.baseBranch || body.config?.baseBranch,
      sizes: { ...DEFAULT_ANALYSIS_CONFIG.sizes, ...body.config?.sizes },
      complexity: { ...DEFAULT_ANALYSIS_CONFIG.complexity, ...body.config?.complexity },
      duplication: { ...DEFAULT_ANALYSIS_CONFIG.duplication, ...body.config?.duplication },
      coupling: { ...DEFAULT_ANALYSIS_CONFIG.coupling, ...body.config?.coupling },
    };

    // Start analysis asynchronously
    const analysisPromise = (async () => {
      try {
        const report = await runAnalysis(repo.path, repoId, config);

        // Write report to repo
        const reportMd = generateReport(report);
        await writeReportToRepo(repo.path, reportMd);

        // Store in database
        const analysisId = await saveAnalysisToDb(db, report);
        await saveMetricsSnapshot(db, report);

        // Update repo last_scan_at
        db.prepare('UPDATE repos SET last_scan_at = ? WHERE id = ?')
          .run(report.timestamp, repoId);

        return { ...report, id: analysisId };
      } finally {
        runningAnalyses.delete(repoId);
      }
    })();

    runningAnalyses.set(repoId, {
      promise: analysisPromise,
      startedAt: new Date().toISOString(),
    });

    // Try to wait briefly for fast repos (up to 2 seconds)
    const raceResult = await Promise.race([
      analysisPromise.then(report => ({ completed: true as const, report })),
      new Promise<{ completed: false }>(resolve =>
        setTimeout(() => resolve({ completed: false }), 2_000)
      ),
    ]);

    if (raceResult.completed) {
      return reply.status(200).send(raceResult.report);
    }

    // Analysis still running — return 202
    return reply.status(202).send({
      status: 'running',
      repoId,
      startedAt: runningAnalyses.get(repoId)?.startedAt,
      message: 'Analysis in progress. Poll GET /api/repos/:repoId/analysis/latest for results.',
    });
  });

  // ── GET /api/repos/:repoId/analysis/latest ───────────────────
  fastify.get<{
    Params: { repoId: string };
  }>('/api/repos/:repoId/analysis/latest', async (request, reply) => {
    const { repoId } = request.params;

    // Validate repo exists
    const repo = db.prepare('SELECT * FROM repos WHERE id = ?').get(repoId);
    if (!repo) {
      return reply.status(404).send({ error: 'Repository not found' });
    }

    const row = db.prepare(
      'SELECT * FROM analyses WHERE repo_id = ? ORDER BY created_at DESC LIMIT 1'
    ).get(repoId);

    if (!row) {
      return reply.status(404).send({ error: 'No analysis found for this repository' });
    }

    const analysisData = JSON.parse(row.analysis_data);
    return reply.send({
      id: row.id,
      ...analysisData,
    });
  });

  // ── GET /api/repos/:repoId/analysis/history ──────────────────
  fastify.get<{
    Params: { repoId: string };
    Querystring: { limit?: string };
  }>('/api/repos/:repoId/analysis/history', async (request, reply) => {
    const { repoId } = request.params;
    const limit = parseInt(request.query.limit || '20', 10);

    // Validate repo exists
    const repo = db.prepare('SELECT * FROM repos WHERE id = ?').get(repoId);
    if (!repo) {
      return reply.status(404).send({ error: 'Repository not found' });
    }

    const rows = db.prepare(
      'SELECT id, repo_id, branch, base_branch, created_at, analysis_data FROM analyses WHERE repo_id = ? ORDER BY created_at DESC LIMIT ?'
    ).all(repoId, limit);

    const history = rows.map((row: any) => {
      const data = JSON.parse(row.analysis_data);
      return {
        id: row.id,
        timestamp: row.created_at,
        branch: row.branch,
        baseBranch: row.base_branch,
        overallStatus: data.overallStatus,
        durationMs: data.durationMs,
        summary: data.summary,
      };
    });

    return reply.send(history);
  });

  // ── GET /api/repos/:repoId/analysis/:analysisId ──────────────
  fastify.get<{
    Params: { repoId: string; analysisId: string };
  }>('/api/repos/:repoId/analysis/:analysisId', async (request, reply) => {
    const { repoId, analysisId } = request.params;

    // Validate repo exists
    const repo = db.prepare('SELECT * FROM repos WHERE id = ?').get(repoId);
    if (!repo) {
      return reply.status(404).send({ error: 'Repository not found' });
    }

    const row = db.prepare(
      'SELECT * FROM analyses WHERE id = ? AND repo_id = ?'
    ).get(analysisId, repoId);

    if (!row) {
      return reply.status(404).send({ error: 'Analysis not found' });
    }

    const analysisData = JSON.parse(row.analysis_data);
    return reply.send({
      id: row.id,
      ...analysisData,
    });
  });
}
```

**Step 2: Register the plugin in the Fastify server**

In `src/server/index.ts`, add the following registration (this is guidance for the implementer, not a file to create in this story):

```typescript
import analysisRoutes from './api/analysis.js';

// Inside server setup:
fastify.register(analysisRoutes);
```

### 3.3 API Contract

| Method | Endpoint | Request Body | Response |
|--------|----------|-------------|----------|
| `POST` | `/api/repos/:repoId/analyze` | `{ baseBranch?: string, config?: Partial<AnalysisConfig> }` | `200` with `AnalysisReport` (if fast) or `202` with `{ status, repoId, startedAt }` |
| `GET` | `/api/repos/:repoId/analysis/latest` | N/A | `200` with `AnalysisReport` or `404` |
| `GET` | `/api/repos/:repoId/analysis/history` | Query: `?limit=N` | `200` with `Array<{ id, timestamp, branch, overallStatus, durationMs, summary }>` |
| `GET` | `/api/repos/:repoId/analysis/:analysisId` | N/A | `200` with `AnalysisReport` or `404` |

**Common error responses:**
- `404 { error: 'Repository not found' }` — repoId does not exist
- `404 { error: 'No analysis found for this repository' }` — no analysis data
- `404 { error: 'Analysis not found' }` — specific analysisId does not exist
- `409 { error: 'Analysis already in progress' }` — duplicate trigger

---

## 4. Definition of Done (The Gate)
- [ ] `src/server/api/analysis.ts` exists and exports a Fastify plugin with all 4 routes.
- [ ] `POST /api/repos/:repoId/analyze` triggers an analysis run and returns 202 (or 200 if fast).
- [ ] `GET /api/repos/:repoId/analysis/latest` returns the most recent analysis.
- [ ] `GET /api/repos/:repoId/analysis/history` returns paginated history ordered by timestamp descending.
- [ ] `GET /api/repos/:repoId/analysis/:analysisId` returns a specific analysis by ID.
- [ ] Invalid repo IDs return 404 with descriptive error messages.
- [ ] Duplicate analysis triggers return 409.
- [ ] The plugin is registered in the Fastify server's route tree.
- [ ] Analysis results are written to `.vibelint/reports/latest.md` and stored in SQLite.
- [ ] Custom config overrides (baseBranch, thresholds) are applied correctly.
- [ ] Integration tests pass covering all endpoints and error cases.
- [ ] No TypeScript compilation errors (`npx tsc --noEmit`).

---
id: STORY-005-08
parent_epic: EPIC-005
status: Draft
actor: Backend Developer
complexity: High (4+ files)
---
# STORY-005-08: Analysis Engine & Report Writer

## 1. The Spec (The Contract)

### 1.1 User Story
**As a** Backend Developer,
**I want** an analysis engine that orchestrates all individual checks, aggregates their results into a unified report, writes a human+AI-readable markdown report to the repo, and stores structured results in SQLite,
**So that** a single `runAnalysis()` call produces a complete analysis that is available on the dashboard, in the repo for the AI agent, and in the database for historical tracking.

### 1.2 Detailed Requirements
- **Requirement 1**: Implement `runAnalysis(repoPath: string, repoId: string, config: AnalysisConfig): Promise<AnalysisReport>` that orchestrates all 7 checks: language detection, file sizes, function sizes, error patterns, complexity, duplication, dependencies, and coupling.
- **Requirement 2**: Run checks in parallel where safe: language detection first (needed by other checks), then file-size + error-patterns + dependencies + coupling in parallel, then complexity + duplication (CLI-based, I/O bound) in parallel.
- **Requirement 3**: Aggregate results into `AnalysisReport` with a `summary` array: `{ check: string, status: 'pass'|'warn'|'fail'|'skipped', details: string }` plus full per-check detail objects.
- **Requirement 4**: Implement `generateReport(report: AnalysisReport, repoName: string): string` that produces the markdown report matching the PRD format (see Section 3.2 below).
- **Requirement 5**: Write the report to `{repoPath}/.vibelint/reports/latest.md`. Create the directory if it does not exist.
- **Requirement 6**: Store the full `AnalysisReport` as JSON in the SQLite `analyses` table: `{ id, repo_id, branch, base_branch, diff_stats, analysis_data, created_at }`.
- **Requirement 7**: Store a metrics snapshot in the `metrics_history` table: `{ repo_id, timestamp, metrics: JSON }` for trending (EPIC-008).
- **Requirement 8**: Compute an overall status: `fail` if any check is `fail`, `warn` if any check is `warn`, `pass` if all checks pass or are skipped.
- **Requirement 9**: Include timing information: total analysis duration and per-check duration.

---

## 2. The Truth (Executable Tests)

### 2.1 Acceptance Criteria (Gherkin)
```gherkin
Feature: Analysis Engine & Report Writer

  Scenario: Run full analysis pipeline
    Given a connected repo at "/tmp/test-repo" with TypeScript files
    When I call runAnalysis with the repo path and ID
    Then all 7 checks are executed
    And the result contains a summary with one entry per check
    And each entry has a status of pass, warn, fail, or skipped
    And the overall status reflects the worst individual status

  Scenario: Markdown report is written to repo
    Given a completed analysis run
    When generateReport is called and the report is written
    Then the file ".vibelint/reports/latest.md" exists in the repo
    And it contains a markdown table with Check, Status, and Details columns
    And it contains a "## Details" section with per-check breakdowns

  Scenario: Results stored in SQLite
    Given a completed analysis run
    When the analysis is saved
    Then a row exists in the "analyses" table with the correct repo_id
    And the analysis_data column contains valid JSON with all check results
    And a row exists in "metrics_history" with a metrics snapshot

  Scenario: Checks run in parallel
    Given a repo with all check types applicable
    When I call runAnalysis
    Then file-size, error-patterns, dependencies, and coupling run concurrently
    And the total time is less than the sum of individual check times

  Scenario: Graceful handling of check failures
    Given Lizard is not installed and jscpd is not installed
    When I call runAnalysis
    Then complexity status is "skipped" and duplication status is "skipped"
    And all other checks complete normally
    And the overall status reflects non-skipped checks only
```

### 2.2 Verification Steps
- [ ] `runAnalysis` calls all 7 analyzer modules and collects results.
- [ ] Parallel execution is used where possible.
- [ ] Markdown report matches the PRD format with summary table and details sections.
- [ ] Report is written to `{repoPath}/.vibelint/reports/latest.md`.
- [ ] Analysis results are stored in SQLite `analyses` table.
- [ ] Metrics snapshot is stored in `metrics_history` table.
- [ ] Overall status is computed correctly from individual check statuses.
- [ ] Timing data is captured for total and per-check durations.
- [ ] Skipped checks (missing CLI tools) do not cause the pipeline to fail.

---

## 3. The Implementation Guide (AI-to-AI)

### 3.1 Context & Files
- **Primary Files**: `src/server/analyzer/engine.ts` (create)
- **Related Files**:
  - `src/server/analyzer/languages/detector.ts` (STORY-005-01)
  - `src/server/analyzer/file-size.ts` (STORY-005-02)
  - `src/server/analyzer/error-patterns.ts` (STORY-005-03)
  - `src/server/analyzer/complexity.ts` (STORY-005-04)
  - `src/server/analyzer/duplication.ts` (STORY-005-05)
  - `src/server/analyzer/dependencies.ts` (STORY-005-06)
  - `src/server/analyzer/coupling.ts` (STORY-005-07)
  - `src/server/db/queries.ts` (database queries — must exist from EPIC-001)
- **New Files Needed**:
  - `src/server/analyzer/engine.ts`
  - `tests/analyzer/engine.test.ts`

### 3.2 Technical Logic

**Step 1: Define types**

```typescript
// src/server/analyzer/engine.ts

import { mkdir, writeFile } from 'node:fs/promises';
import { join } from 'node:path';
import { detectLanguages, DetectionResult } from './languages/detector.js';
import { checkSizes, SizeCheckResult, SizeConfig, DEFAULT_SIZE_CONFIG } from './file-size.js';
import { checkErrorHandling, ErrorPatternResult } from './error-patterns.js';
import { analyzeComplexity, ComplexityResult, ComplexityConfig, DEFAULT_COMPLEXITY_CONFIG } from './complexity.js';
import { detectDuplication, DuplicationResult, DuplicationConfig, DEFAULT_DUPLICATION_CONFIG } from './duplication.js';
import { checkDependencies, detectNewDependencies, DependencyResult } from './dependencies.js';
import { analyzeCoupling, CouplingResult, CouplingConfig, DEFAULT_COUPLING_CONFIG } from './coupling.js';

export type CheckStatus = 'pass' | 'warn' | 'fail' | 'skipped';

export interface CheckSummary {
  check: string;
  status: CheckStatus;
  details: string;
  durationMs: number;
}

export interface AnalysisConfig {
  sizes: SizeConfig;
  complexity: ComplexityConfig;
  duplication: DuplicationConfig;
  coupling: CouplingConfig;
  baseBranch?: string;
}

export const DEFAULT_ANALYSIS_CONFIG: AnalysisConfig = {
  sizes: DEFAULT_SIZE_CONFIG,
  complexity: DEFAULT_COMPLEXITY_CONFIG,
  duplication: DEFAULT_DUPLICATION_CONFIG,
  coupling: DEFAULT_COUPLING_CONFIG,
};

export interface AnalysisReport {
  repoId: string;
  repoPath: string;
  repoName: string;
  timestamp: string;         // ISO 8601
  branch?: string;
  baseBranch?: string;
  overallStatus: CheckStatus;
  durationMs: number;
  summary: CheckSummary[];
  details: {
    languages: DetectionResult;
    sizes: SizeCheckResult;
    errorPatterns: ErrorPatternResult;
    complexity: ComplexityResult;
    duplication: DuplicationResult;
    dependencies: DependencyResult;
    coupling: CouplingResult;
  };
}
```

**Step 2: Helper to time a check**

```typescript
async function timedCheck<T>(
  name: string,
  fn: () => Promise<T>
): Promise<{ result: T; durationMs: number }> {
  const start = performance.now();
  const result = await fn();
  const durationMs = Math.round(performance.now() - start);
  return { result, durationMs };
}
```

**Step 3: Build summary detail strings**

```typescript
function sizeSummary(result: SizeCheckResult): string {
  if (result.filesOverThreshold === 0 && result.functionsOverThreshold === 0) {
    return `All files and functions within limits`;
  }
  const parts: string[] = [];
  if (result.filesOverThreshold > 0) {
    parts.push(`${result.filesOverThreshold} file(s) over line limit`);
  }
  if (result.functionsOverThreshold > 0) {
    parts.push(`${result.functionsOverThreshold} function(s) too long`);
  }
  return parts.join('; ');
}

function errorSummary(result: ErrorPatternResult): string {
  if (result.issues.length === 0) return 'No issues found';
  const errors = result.issues.filter(i => i.severity === 'error').length;
  const warnings = result.issues.filter(i => i.severity === 'warning').length;
  const parts: string[] = [];
  if (errors > 0) parts.push(`${errors} error(s)`);
  if (warnings > 0) parts.push(`${warnings} warning(s)`);
  return parts.join(', ');
}

function complexitySummary(result: ComplexityResult): string {
  if (!result.available) return result.reason || 'Not available';
  if (result.functions.length === 0) return `Avg CCN: ${result.summary.avgComplexity}`;
  return `${result.summary.failCount} fail, ${result.summary.warnCount} warn (max: ${result.summary.maxComplexity})`;
}

function duplicationSummary(result: DuplicationResult): string {
  if (!result.available) return result.reason || 'Not available';
  return `${result.percentage}% duplicated (${result.clones.length} clone(s))`;
}

function dependencySummary(result: DependencyResult): string {
  if (result.manifests.length === 0) return 'No manifests found';
  const newCount = result.totalNewDeps;
  if (newCount > 0) return `${result.totalDeps} deps, ${newCount} new`;
  return `${result.totalDeps} deps`;
}

function couplingSummary(result: CouplingResult): string {
  if (result.status === 'skipped') return result.reason || 'Skipped';
  return `${result.dirsChanged} dirs, ${result.filesChanged} files changed`;
}
```

**Step 4: Implement runAnalysis**

```typescript
export async function runAnalysis(
  repoPath: string,
  repoId: string,
  config: AnalysisConfig = DEFAULT_ANALYSIS_CONFIG
): Promise<AnalysisReport> {
  const startTime = performance.now();
  const timestamp = new Date().toISOString();
  const repoName = repoPath.split('/').pop() || repoId;

  // Phase 1: Language detection (needed by error patterns)
  const langTimed = await timedCheck('Languages', () => detectLanguages(repoPath));
  const languageNames = langTimed.result.languages.map(l => l.language);

  // Phase 2: Parallel — file-independent checks
  const [sizeTimed, errorTimed, depTimed, couplingTimed] = await Promise.all([
    timedCheck('File Size', () => checkSizes(repoPath, config.sizes)),
    timedCheck('Error Handling', () => checkErrorHandling(repoPath, languageNames)),
    timedCheck('Dependencies', () =>
      config.baseBranch
        ? detectNewDependencies(repoPath, config.baseBranch)
        : checkDependencies(repoPath)
    ),
    timedCheck('Coupling', () => analyzeCoupling(repoPath, config.baseBranch, config.coupling)),
  ]);

  // Phase 3: Parallel — CLI-based checks (I/O bound)
  const [complexityTimed, duplicationTimed] = await Promise.all([
    timedCheck('Complexity', () => analyzeComplexity(repoPath, config.complexity, languageNames)),
    timedCheck('Duplication', () => detectDuplication(repoPath, config.duplication)),
  ]);

  // Build summary
  const summary: CheckSummary[] = [
    { check: 'File Size', status: sizeTimed.result.status, details: sizeSummary(sizeTimed.result), durationMs: sizeTimed.durationMs },
    { check: 'Error Handling', status: errorTimed.result.status, details: errorSummary(errorTimed.result), durationMs: errorTimed.durationMs },
    { check: 'Complexity', status: complexityTimed.result.status, details: complexitySummary(complexityTimed.result), durationMs: complexityTimed.durationMs },
    { check: 'Duplication', status: duplicationTimed.result.status, details: duplicationSummary(duplicationTimed.result), durationMs: duplicationTimed.durationMs },
    { check: 'Dependencies', status: depTimed.result.status, details: dependencySummary(depTimed.result), durationMs: depTimed.durationMs },
    { check: 'Coupling', status: couplingTimed.result.status, details: couplingSummary(couplingTimed.result), durationMs: couplingTimed.durationMs },
  ];

  // Compute overall status (ignore 'skipped')
  const activeStatuses = summary
    .map(s => s.status)
    .filter(s => s !== 'skipped');
  let overallStatus: CheckStatus = 'pass';
  if (activeStatuses.includes('fail')) overallStatus = 'fail';
  else if (activeStatuses.includes('warn')) overallStatus = 'warn';

  const durationMs = Math.round(performance.now() - startTime);

  // Get current branch name
  let branch: string | undefined;
  try {
    const { execCommand } = await import('../utils/exec.js');
    const { stdout } = await execCommand('git', ['branch', '--show-current'], { cwd: repoPath, timeoutMs: 5_000 });
    branch = stdout.trim();
  } catch { /* not a git repo or no branch */ }

  const report: AnalysisReport = {
    repoId,
    repoPath,
    repoName,
    timestamp,
    branch,
    baseBranch: config.baseBranch,
    overallStatus,
    durationMs,
    summary,
    details: {
      languages: langTimed.result,
      sizes: sizeTimed.result,
      errorPatterns: errorTimed.result,
      complexity: complexityTimed.result,
      duplication: duplicationTimed.result,
      dependencies: depTimed.result,
      coupling: couplingTimed.result,
    },
  };

  return report;
}
```

**Step 5: Implement generateReport (Markdown)**

```typescript
const STATUS_ICONS: Record<CheckStatus, string> = {
  pass: 'PASS',
  warn: 'WARN',
  fail: 'FAIL',
  skipped: 'SKIP',
};

export function generateReport(report: AnalysisReport): string {
  const lines: string[] = [];

  lines.push(`# Analysis Report — ${report.repoName}`);
  lines.push(`Generated: ${report.timestamp}`);
  lines.push('');

  if (report.branch) {
    const branchLine = report.baseBranch
      ? `## Branch: ${report.branch} vs ${report.baseBranch}`
      : `## Branch: ${report.branch}`;
    lines.push(branchLine);
    if (report.details.coupling.filesChanged > 0) {
      lines.push(`Files changed: ${report.details.coupling.filesChanged} | +${report.details.coupling.insertions} -${report.details.coupling.deletions}`);
    }
    lines.push('');
  }

  // Languages
  if (report.details.languages.languages.length > 0) {
    lines.push(`## Languages`);
    lines.push(report.details.languages.languages.map(l => `${l.language} (${l.percentage}%)`).join(', '));
    lines.push('');
  }

  // Summary table
  lines.push('## Summary');
  lines.push('| Check | Status | Details |');
  lines.push('|-------|--------|---------|');
  for (const entry of report.summary) {
    lines.push(`| ${entry.check} | ${STATUS_ICONS[entry.status]} | ${entry.details} |`);
  }
  lines.push('');

  // Details sections
  lines.push('## Details');
  lines.push('');

  // File Size details
  if (report.details.sizes.files.length > 0) {
    lines.push('### File Size');
    for (const file of report.details.sizes.files) {
      lines.push(`- **${file.path}**: ${file.lines} lines`);
      for (const fn of file.functions) {
        lines.push(`  - \`${fn.name}\`: ${fn.lines} lines (line ${fn.startLine})`);
      }
    }
    lines.push('');
  }

  // Error Handling details
  if (report.details.errorPatterns.issues.length > 0) {
    lines.push('### Error Handling');
    for (const issue of report.details.errorPatterns.issues) {
      lines.push(`- **${issue.file}:${issue.line}** — ${issue.pattern} [${issue.severity}]`);
      if (issue.snippet) {
        lines.push(`  \`${issue.snippet}\``);
      }
    }
    lines.push('');
  }

  // Complexity details
  if (report.details.complexity.available && report.details.complexity.functions.length > 0) {
    lines.push('### Complexity');
    lines.push(`Average: ${report.details.complexity.summary.avgComplexity} | Max: ${report.details.complexity.summary.maxComplexity}`);
    lines.push('');
    for (const fn of report.details.complexity.functions) {
      lines.push(`- **${fn.file}** \`${fn.name}\`: CCN=${fn.complexity}, NLOC=${fn.nloc} [${fn.flag}]`);
    }
    lines.push('');
  }

  // Duplication details
  if (report.details.duplication.available && report.details.duplication.clones.length > 0) {
    lines.push('### Duplication');
    lines.push(`Total: ${report.details.duplication.percentage}% duplicated`);
    lines.push('');
    for (const clone of report.details.duplication.clones) {
      lines.push(`- **${clone.firstFile}** (lines ${clone.firstStartLine}-${clone.firstEndLine}) <-> **${clone.secondFile}** (lines ${clone.secondStartLine}-${clone.secondEndLine}) — ${clone.lines} lines`);
    }
    lines.push('');
  }

  // Dependencies details
  if (report.details.dependencies.manifests.length > 0) {
    lines.push('### Dependencies');
    for (const manifest of report.details.dependencies.manifests) {
      const newInfo = manifest.newDeps.length > 0
        ? ` (new: ${manifest.newDeps.join(', ')})`
        : '';
      lines.push(`- **${manifest.file}**: ${manifest.depCount} dependencies${newInfo}`);
    }
    lines.push('');
  }

  // Coupling details
  if (report.details.coupling.status !== 'skipped' && report.details.coupling.fileList.length > 0) {
    lines.push('### Coupling');
    lines.push(`Directories touched: ${report.details.coupling.dirsChanged} | Files: ${report.details.coupling.filesChanged}`);
    lines.push('');
    for (const dir of report.details.coupling.dirList) {
      lines.push(`- ${dir}/`);
    }
    lines.push('');
  }

  // Footer
  lines.push('---');
  lines.push(`*Analysis completed in ${report.durationMs}ms*`);

  return lines.join('\n');
}
```

**Step 6: Write report to repo and store in database**

```typescript
export async function writeReportToRepo(
  repoPath: string,
  reportMarkdown: string
): Promise<string> {
  const reportsDir = join(repoPath, '.vibelint', 'reports');
  await mkdir(reportsDir, { recursive: true });
  const reportPath = join(reportsDir, 'latest.md');
  await writeFile(reportPath, reportMarkdown, 'utf-8');
  return reportPath;
}

export async function saveAnalysisToDb(
  db: any, // better-sqlite3 Database instance
  report: AnalysisReport
): Promise<number> {
  const stmt = db.prepare(`
    INSERT INTO analyses (repo_id, branch, base_branch, diff_stats, analysis_data, created_at)
    VALUES (?, ?, ?, ?, ?, ?)
  `);

  const diffStats = JSON.stringify({
    filesChanged: report.details.coupling.filesChanged,
    insertions: report.details.coupling.insertions,
    deletions: report.details.coupling.deletions,
  });

  const result = stmt.run(
    report.repoId,
    report.branch || null,
    report.baseBranch || null,
    diffStats,
    JSON.stringify(report),
    report.timestamp
  );

  return result.lastInsertRowid as number;
}

export async function saveMetricsSnapshot(
  db: any, // better-sqlite3 Database instance
  report: AnalysisReport
): Promise<void> {
  const metrics = {
    overallStatus: report.overallStatus,
    complexity: report.details.complexity.summary,
    duplication: { percentage: report.details.duplication.percentage },
    fileSize: {
      filesOverThreshold: report.details.sizes.filesOverThreshold,
      functionsOverThreshold: report.details.sizes.functionsOverThreshold,
    },
    errorPatterns: { issueCount: report.details.errorPatterns.issues.length },
    dependencies: { totalDeps: report.details.dependencies.totalDeps },
    coupling: {
      dirsChanged: report.details.coupling.dirsChanged,
      filesChanged: report.details.coupling.filesChanged,
    },
  };

  const stmt = db.prepare(`
    INSERT INTO metrics_history (repo_id, timestamp, metrics)
    VALUES (?, ?, ?)
  `);

  stmt.run(report.repoId, report.timestamp, JSON.stringify(metrics));
}
```

### 3.3 API Contract
N/A — this module is consumed by the Analysis API (STORY-005-09). It does not define HTTP endpoints itself.

---

## 4. Definition of Done (The Gate)
- [ ] `src/server/analyzer/engine.ts` exists and exports `runAnalysis`, `generateReport`, `writeReportToRepo`, `saveAnalysisToDb`, `saveMetricsSnapshot`, and all related types.
- [ ] `runAnalysis` orchestrates all 7 checks and returns a complete `AnalysisReport`.
- [ ] Checks are parallelized: file-size + error-patterns + dependencies + coupling together, then complexity + duplication together.
- [ ] `generateReport` produces markdown matching the PRD format: title, branch info, summary table, details sections.
- [ ] `writeReportToRepo` creates `.vibelint/reports/latest.md` in the target repo.
- [ ] `saveAnalysisToDb` inserts a row into the `analyses` table with JSON-serialized results.
- [ ] `saveMetricsSnapshot` inserts a row into the `metrics_history` table.
- [ ] Overall status is computed correctly: fail > warn > pass (skipped checks ignored).
- [ ] Timing data is captured for total duration and each individual check.
- [ ] Skipped checks (Lizard/jscpd not installed) do not break the pipeline.
- [ ] Unit tests pass covering orchestration, report generation, and database storage.
- [ ] No TypeScript compilation errors (`npx tsc --noEmit`).
